{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89514b0e",
   "metadata": {},
   "source": [
    "# File Structure\n",
    "```\n",
    "┖ dataset - 데이터셋 파일 위치\n",
    "    ┖ train.h5\n",
    "    ┖ test.h5\n",
    "    ┖ train.csv\n",
    "    ┖ sample_submission.csv\n",
    "┖ Final_code.ipynb - 전체 코드 실행 파일\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86404b8",
   "metadata": {},
   "source": [
    "# Load library and variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c1ce1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#사용 모듈\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import time\n",
    "from sklearn.decomposition import PCA, KernelPCA, SparsePCA, FastICA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py # .h5 파일을 읽기 위한 패키지\n",
    "import cv2\n",
    "import glob\n",
    "from os.path import join as opj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4dbbe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#변수 준비\n",
    "\n",
    "debug = False\n",
    "CFG = {\n",
    "    'CLF_LR': 0.0001,\n",
    "    'BATCH_SIZE': 64,\n",
    "    'SEED': 42,\n",
    "    'MODEL_NAME': 'densenet161',\n",
    "    'MODEL_NAME_2': 'tf_efficientnet_b4_ns',\n",
    "    'MODEL_NAME_3': 'xception',\n",
    "    'EPOCHS': 40,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfce5476",
   "metadata": {},
   "source": [
    "# 3d->2d using PCA\n",
    "onlygoodman님의 접근방식을 참고했습니다.\n",
    "\n",
    "https://dacon.io/competitions/official/235951/codeshare/6476"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6add2e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = h5py.File('./dataset/train.h5', 'r')\n",
    "test_all = h5py.File('./dataset/test.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a5e32a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = f'./dataset/trainimage_224NPCA/'\n",
    "test_dir = f'./dataset/testimage_224NPCA/'\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dc4077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data 준비, 224\n",
    "\n",
    "count = 0\n",
    "failcount = 0 \n",
    "\n",
    "#pca = SparsePCA(n_components=2), trainimage_224SPCA\n",
    "pca = PCA(n_components=2)\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "for i in tqdm(range(50000)):\n",
    "    if True:\n",
    "        testdata = np.array(train_all[str(i)])\n",
    "        \n",
    "        #3차원 -> 2차원으로 축소\n",
    "        df_pca = pca.fit_transform(testdata)\n",
    "        x = df_pca[:, 0]\n",
    "        y = df_pca[:, 1]\n",
    "        plt.axis('off')\n",
    "        #산점도의 점크기 -> s=1로 하면 사진이 너무 두꺼워짐\n",
    "        plt.scatter(x, y, s=0.2, c=\"black\")\n",
    "        \n",
    "        #224*224 size로 저장\n",
    "        plt.savefig('./dataset/trainimage_224NPCA/train_image{:0>5}.jpg'.format(i), dpi=28)\n",
    "        plt.cla()\n",
    "        count+=1\n",
    "        \n",
    "    else:\n",
    "        failcount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95acadc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data 준비, 224\n",
    "\n",
    "count = 0\n",
    "failcount = 0 \n",
    "\n",
    "#pca = SparsePCA(n_components=2), testimage_224SPCA\n",
    "pca = PCA(n_components=2)\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "    \n",
    "for i in tqdm(range(40000)):\n",
    "    if True:\n",
    "        testdata = np.array(test_all[str(i+50000)])\n",
    "        \n",
    "        #3차원 -> 2차원으로 축소\n",
    "        df_pca = pca.fit_transform(testdata)\n",
    "        x = df_pca[:, 0]\n",
    "        y = df_pca[:, 1]\n",
    "        plt.axis('off')\n",
    "        #산점도의 점크기 -> s=1로 하면 사진이 너무 두꺼워짐\n",
    "        plt.scatter(x, y, s=0.2, c=\"black\")\n",
    "        \n",
    "        #224*224 size로 저장\n",
    "        plt.savefig('./dataset/testimage_224NPCA/test_image{:0>5}.jpg'.format(i), dpi=28)\n",
    "        plt.cla()\n",
    "        count+=1\n",
    "        \n",
    "    else:\n",
    "        failcount += 1   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5d3385",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95e1da1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import timm\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56d27071",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier_Dataset(Dataset):\n",
    "  def __init__(self, df):\n",
    "    self.df = df\n",
    "  def __len__(self):\n",
    "    return len(self.df)\n",
    "  def __getitem__(self, idx):\n",
    "    img = cv2.imread(self.df.iloc[idx, 0], cv2.IMREAD_GRAYSCALE)\n",
    "    img = img / 255\n",
    "    img = torch.Tensor(img)[None, :]\n",
    "\n",
    "    label = self.df.iloc[idx, 1]\n",
    "    label = torch.eye(10)[label]\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2212e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Case_Classifier(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super(Case_Classifier, self).__init__()\n",
    "        self.model = timm.create_model(name, pretrained = True, num_classes = 10, in_chans=1)\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x) #1층\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0edbad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d31ca1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d59ad5",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "720263fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c87933053e574a33b8e398e82007e2d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./dataset/trainimage_224NPCA\\train_image00000.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./dataset/trainimage_224NPCA\\train_image00001.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./dataset/trainimage_224NPCA\\train_image00002.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./dataset/trainimage_224NPCA\\train_image00003.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./dataset/trainimage_224NPCA\\train_image00004.jpg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          train_path  label\n",
       "0  ./dataset/trainimage_224NPCA\\train_image00000.jpg      5\n",
       "1  ./dataset/trainimage_224NPCA\\train_image00001.jpg      0\n",
       "2  ./dataset/trainimage_224NPCA\\train_image00002.jpg      4\n",
       "3  ./dataset/trainimage_224NPCA\\train_image00003.jpg      1\n",
       "4  ./dataset/trainimage_224NPCA\\train_image00004.jpg      9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_paths = sorted(glob.glob('./dataset/trainimage_224NPCA/*.jpg'))\n",
    "\n",
    "train_df = pd.DataFrame({'train_path':train_paths})\n",
    "label_df = pd.read_csv('./dataset/train.csv')\n",
    "\n",
    "train_label = []\n",
    "for i in tqdm(range(len(train_df))):\n",
    "    train_label.append(label_df[label_df['ID'] == int(train_df.iloc[i][0][-9:-4])]['label'].iloc[0])\n",
    "\n",
    "train_df['label'] = train_label\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa7a4b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 5678, 7: 5175, 3: 5101, 9: 4988, 2: 4968, 6: 4951, 0: 4932, 4: 4859, 8: 4842, 5: 4506})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "cnt = Counter(train_label)\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0dcc0c",
   "metadata": {},
   "source": [
    "## Train Densenet161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f00971",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "model_dir = f'./model/'+CFG['MODEL_NAME']\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "print(model_dir)\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=CFG['SEED'])\n",
    "for i, [train_idx, val_idx] in enumerate(kf.split(train_df, train_df['label'])):\n",
    "    if i == 3:\n",
    "        break\n",
    "    print('########## %dth train ##########' %(i))\n",
    "    \n",
    "    seed_everything(CFG['SEED']) # Seed 고정\n",
    "    \n",
    "    df_train = train_df.iloc[train_idx]\n",
    "    df_val = train_df.iloc[val_idx]\n",
    "\n",
    "    cls_set = Classifier_Dataset(df_train)\n",
    "    cls_val_set = Classifier_Dataset(df_val)\n",
    "    cls_loader = DataLoader(cls_set, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "    cls_val_loader = DataLoader(cls_val_set, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "    classifier = Case_Classifier(CFG['MODEL_NAME'])\n",
    "    classifier.to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(params=classifier.parameters(), lr=CFG['CLF_LR'])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5, factor=0.5)\n",
    "    \n",
    "    best_acc = 0\n",
    "    np.set_printoptions(precision=6, suppress=True)\n",
    "    for epoch in range(CFG['EPOCHS']):\n",
    "      train_losses = []\n",
    "      val_losses = []\n",
    "      accuracy = 0\n",
    "      \n",
    "      classifier.train()\n",
    "      for img, label in tqdm(cls_loader):\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = classifier(img)\n",
    "        loss = criterion(label, pred)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "      \n",
    "      classifier.eval()\n",
    "\n",
    "      with torch.no_grad():\n",
    "        for img, label in tqdm(cls_val_loader):\n",
    "          img = img.to(device)\n",
    "          label = label.to(device)\n",
    "\n",
    "          pred = classifier(img)\n",
    "          loss = criterion(label, pred)\n",
    "          val_losses.append(loss.item())\n",
    "\n",
    "          label = label.argmax(dim=1)\n",
    "          pred = pred.argmax(dim=1)\n",
    "          acc = (label==pred).count_nonzero()\n",
    "          accuracy += acc.item() / len(cls_val_set)\n",
    "        \n",
    "      if best_acc < accuracy:\n",
    "        torch.save(classifier.state_dict(), model_dir+f'/cnn_classifier_{i}.pth')\n",
    "        print('##########Model Saved!##########')\n",
    "        best_acc = accuracy\n",
    "\n",
    "\n",
    "      if scheduler is not None:\n",
    "        scheduler.step(accuracy)\n",
    "\n",
    "      train_losses = np.mean(train_losses)\n",
    "      val_losses = np.mean(val_losses)\n",
    "\n",
    "      print(f'[EPOCH:{epoch+1}/{CFG[\"EPOCHS\"]}] [Train Loss:{train_losses}] [Val Loss:{val_losses}] [Val Accuracy:{accuracy}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a41981d",
   "metadata": {},
   "source": [
    "## Train efficientnet_b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49b8677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "model_dir = f'./model/'+CFG['MODEL_NAME_2']\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "print(model_dir)\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=CFG['SEED'])\n",
    "for i, [train_idx, val_idx] in enumerate(kf.split(train_df, train_df['label'])):\n",
    "    if i < 3:\n",
    "        continue\n",
    "    if i == 6:\n",
    "        break\n",
    "    print('########## %dth train ##########' %(i))\n",
    "    \n",
    "    seed_everything(CFG['SEED']) # Seed 고정\n",
    "    \n",
    "    df_train = train_df.iloc[train_idx]\n",
    "    df_val = train_df.iloc[val_idx]\n",
    "\n",
    "    cls_set = Classifier_Dataset(df_train)\n",
    "    cls_val_set = Classifier_Dataset(df_val)\n",
    "    cls_loader = DataLoader(cls_set, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "    cls_val_loader = DataLoader(cls_val_set, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "    classifier = Case_Classifier(CFG['MODEL_NAME_2'])\n",
    "    classifier.to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(params=classifier.parameters(), lr=CFG['CLF_LR'])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5, factor=0.5)\n",
    "    \n",
    "    best_acc = 0\n",
    "    np.set_printoptions(precision=6, suppress=True)\n",
    "    for epoch in range(CFG['EPOCHS']):\n",
    "      train_losses = []\n",
    "      val_losses = []\n",
    "      accuracy = 0\n",
    "      \n",
    "      classifier.train()\n",
    "      for img, label in tqdm(cls_loader):\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = classifier(img)\n",
    "        loss = criterion(label, pred)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "      \n",
    "      classifier.eval()\n",
    "\n",
    "      with torch.no_grad():\n",
    "        for img, label in tqdm(cls_val_loader):\n",
    "          img = img.to(device)\n",
    "          label = label.to(device)\n",
    "\n",
    "          pred = classifier(img)\n",
    "          loss = criterion(label, pred)\n",
    "          val_losses.append(loss.item())\n",
    "\n",
    "          label = label.argmax(dim=1)\n",
    "          pred = pred.argmax(dim=1)\n",
    "          acc = (label==pred).count_nonzero()\n",
    "          accuracy += acc.item() / len(cls_val_set)\n",
    "        \n",
    "      if best_acc < accuracy:\n",
    "        torch.save(classifier.state_dict(), model_dir+f'/cnn_classifier_{i}.pth')\n",
    "        print('##########Model Saved!##########')\n",
    "        best_acc = accuracy\n",
    "\n",
    "\n",
    "      if scheduler is not None:\n",
    "        scheduler.step(accuracy)\n",
    "\n",
    "      train_losses = np.mean(train_losses)\n",
    "      val_losses = np.mean(val_losses)\n",
    "\n",
    "      print(f'[EPOCH:{epoch+1}/{CFG[\"EPOCHS\"]}] [Train Loss:{train_losses}] [Val Loss:{val_losses}] [Val Accuracy:{accuracy}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5fa825",
   "metadata": {},
   "source": [
    "## Train xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f01942",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "model_dir = f'./model/'+CFG['MODEL_NAME_3']\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "print(model_dir)\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=CFG['SEED'])\n",
    "for i, [train_idx, val_idx] in enumerate(kf.split(train_df, train_df['label'])):\n",
    "    if i < 6:\n",
    "        continue\n",
    "    if i == 9:\n",
    "        break\n",
    "    print('########## %dth train ##########' %(i))\n",
    "    \n",
    "    seed_everything(CFG['SEED']) # Seed 고정\n",
    "    \n",
    "    df_train = train_df.iloc[train_idx]\n",
    "    df_val = train_df.iloc[val_idx]\n",
    "\n",
    "    cls_set = Classifier_Dataset(df_train)\n",
    "    cls_val_set = Classifier_Dataset(df_val)\n",
    "    cls_loader = DataLoader(cls_set, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "    cls_val_loader = DataLoader(cls_val_set, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "    classifier = Case_Classifier(CFG['MODEL_NAME_3'])\n",
    "    classifier.to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(params=classifier.parameters(), lr=CFG['CLF_LR'])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5, factor=0.5)\n",
    "    \n",
    "    best_acc = 0\n",
    "    np.set_printoptions(precision=6, suppress=True)\n",
    "    for epoch in range(CFG['EPOCHS']):\n",
    "      train_losses = []\n",
    "      val_losses = []\n",
    "      accuracy = 0\n",
    "      \n",
    "      classifier.train()\n",
    "      for img, label in tqdm(cls_loader):\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = classifier(img)\n",
    "        loss = criterion(label, pred)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "      \n",
    "      classifier.eval()\n",
    "\n",
    "      with torch.no_grad():\n",
    "        for img, label in tqdm(cls_val_loader):\n",
    "          img = img.to(device)\n",
    "          label = label.to(device)\n",
    "\n",
    "          pred = classifier(img)\n",
    "          loss = criterion(label, pred)\n",
    "          val_losses.append(loss.item())\n",
    "\n",
    "          label = label.argmax(dim=1)\n",
    "          pred = pred.argmax(dim=1)\n",
    "          acc = (label==pred).count_nonzero()\n",
    "          accuracy += acc.item() / len(cls_val_set)\n",
    "        \n",
    "      if best_acc < accuracy:\n",
    "        torch.save(classifier.state_dict(), model_dir+f'/cnn_classifier_{i}.pth')\n",
    "        print('##########Model Saved!##########')\n",
    "        best_acc = accuracy\n",
    "\n",
    "\n",
    "      if scheduler is not None:\n",
    "        scheduler.step(accuracy)\n",
    "\n",
    "      train_losses = np.mean(train_losses)\n",
    "      val_losses = np.mean(val_losses)\n",
    "\n",
    "      print(f'[EPOCH:{epoch+1}/{CFG[\"EPOCHS\"]}] [Train Loss:{train_losses}] [Val Loss:{val_losses}] [Val Accuracy:{accuracy}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104f4b89",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d1426774",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inference_Dataset(Dataset):\n",
    "  def __init__(self, df):\n",
    "    self.df = df\n",
    "  def __len__(self):\n",
    "    return len(self.df)\n",
    "  def __getitem__(self, idx):\n",
    "    img1 = cv2.imread(self.df.iloc[idx, 0], cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    img1 = img1 /255.0\n",
    "    \n",
    "    img1 = torch.Tensor(img1)[None, :]\n",
    "\n",
    "    return img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7b4ce3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "model_dir = f'./model/'+CFG['MODEL_NAME']\n",
    "model_dir_2 = f'./model/'+CFG['MODEL_NAME_2']\n",
    "model_dir_3 = f'./model/'+CFG['MODEL_NAME_3']\n",
    "\n",
    "for i in range(3):\n",
    "    classifier = Case_Classifier(CFG['MODEL_NAME'])\n",
    "    model_path = model_dir+f'/cnn_classifier_{i}.pth'\n",
    "    classifier.load_state_dict(torch.load(model_path))\n",
    "    classifier.to(device)\n",
    "    classifier.eval()\n",
    "    models.append(classifier)\n",
    "    \n",
    "for i in range(3,6):\n",
    "    classifier = Case_Classifier(CFG['MODEL_NAME_2'])\n",
    "    model_path = model_dir_2+f'/cnn_classifier_{i}.pth'\n",
    "    classifier.load_state_dict(torch.load(model_path))\n",
    "    classifier.to(device)\n",
    "    classifier.eval()\n",
    "    models.append(classifier)\n",
    "    \n",
    "for i in range(6,9):\n",
    "    classifier = Case_Classifier(CFG['MODEL_NAME_3'])\n",
    "    model_path = model_dir_3+f'/cnn_classifier_{i}.pth'\n",
    "    classifier.load_state_dict(torch.load(model_path))\n",
    "    classifier.to(device)\n",
    "    classifier.eval()\n",
    "    models.append(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6a3f1b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6b16bc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./dataset/testimage_224NPCA\\test_image00000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./dataset/testimage_224NPCA\\test_image00001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./dataset/testimage_224NPCA\\test_image00002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./dataset/testimage_224NPCA\\test_image00003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./dataset/testimage_224NPCA\\test_image00004.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         test_path\n",
       "0  ./dataset/testimage_224NPCA\\test_image00000.jpg\n",
       "1  ./dataset/testimage_224NPCA\\test_image00001.jpg\n",
       "2  ./dataset/testimage_224NPCA\\test_image00002.jpg\n",
       "3  ./dataset/testimage_224NPCA\\test_image00003.jpg\n",
       "4  ./dataset/testimage_224NPCA\\test_image00004.jpg"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_paths = sorted(glob.glob('./dataset/testimage_224NPCA/*.jpg'))\n",
    "\n",
    "test_df = pd.DataFrame({'test_path':test_paths})\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "35b3e378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07625ed3c68a43ba868cff4951534258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = Inference_Dataset(test_df)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)\n",
    "\n",
    "n = 0\n",
    "\n",
    "result_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img1 in tqdm(iter(test_loader)):\n",
    "        label_pred = []\n",
    "        \n",
    "        img1 = img1.to(device)\n",
    "        \n",
    "        for i in range(len(models)):\n",
    "            label_pred.append(models[i](img1))\n",
    "            \n",
    "        standard = label_pred[0]\n",
    "        for i in range(1, len(label_pred)):\n",
    "            standard = standard + label_pred[i]\n",
    "        \n",
    "        for i in range(len(standard)):\n",
    "            label = standard[i].argmax(dim=0).item()\n",
    "            result_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c100094d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 4450, 7: 4170, 2: 4124, 3: 4070, 8: 4014, 4: 3986, 0: 3970, 9: 3952, 6: 3708, 5: 3556})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "cnt = Counter(result_list)\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fa2e077a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50002</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50003</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50004</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  label\n",
       "0  50000      7\n",
       "1  50001      2\n",
       "2  50002      2\n",
       "3  50003      4\n",
       "4  50004      9"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.read_csv('./dataset/sample_submission.csv')\n",
    "submission_df['label'] = result_list\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0393ea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('./submit_5.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
